{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037307c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted for blurred_IMG_20230410_130327.jpg\n",
      "Features extracted for blurred_IMG_20230410_130352.jpg\n",
      "Features extracted for blurred_IMG_20230410_130733.jpg\n",
      "Features extracted for blurred_IMG_20230410_130823.jpg\n",
      "Features extracted for blurred_IMG_20230410_130913.jpg\n",
      "Features extracted for blurred_IMG_20230410_131008.jpg\n",
      "Features extracted for blurred_IMG_20230410_131353.jpg\n",
      "Features extracted for blurred_IMG_20230410_132726.jpg\n",
      "Features extracted for blurred_IMG_20230410_132758.jpg\n",
      "Features extracted for blurred_IMG_20230410_132823.jpg\n",
      "Features extracted for blurred_IMG_20230410_134317.jpg\n",
      "Features extracted for blurred_IMG_20230410_134343.jpg\n",
      "Features extracted for blurred_IMG_20230410_134455.jpg\n",
      "Features extracted for blurred_IMG_20230410_134518.jpg\n",
      "Features extracted for blurred_IMG_20230410_135002.jpg\n",
      "Features extracted for blurred_IMG_20230410_135018.jpg\n",
      "Features extracted for blurred_IMG_20230410_135707.jpg\n",
      "Features extracted for blurred_IMG_20230410_140201_1.jpg\n",
      "Features extracted for blurred_IMG_20230410_141229.jpg\n",
      "Features extracted for blurred_IMG_20230410_141237.jpg\n",
      "Features extracted for blurred_IMG_20230410_141253.jpg\n",
      "Features extracted for blurred_IMG_20230410_141341.jpg\n",
      "Features extracted for blurred_IMG_20230410_141350.jpg\n",
      "Features extracted for blurred_IMG_20230410_141456.jpg\n",
      "Features extracted for blurred_IMG_20230410_141525.jpg\n",
      "Features extracted for blurred_IMG_20230410_141604.jpg\n",
      "Features extracted for blurred_IMG_20230410_141612.jpg\n",
      "Features extracted for blurred_IMG_20230410_141617.jpg\n",
      "Features extracted for blurred_IMG_20230410_141657.jpg\n",
      "Features extracted for blurred_IMG_20230410_141801.jpg\n",
      "Features extracted for blurred_IMG_20230410_141919.jpg\n",
      "Features extracted for blurred_IMG_20230410_142011.jpg\n",
      "Features extracted for blurred_IMG_20230410_142016.jpg\n",
      "Features extracted for blurred_IMG_20230410_143128.jpg\n",
      "Features extracted for blurred_IMG_20230410_143146.jpg\n",
      "Features extracted for blurred_IMG_20230410_143505.jpg\n",
      "Features extracted for blurred_IMG_20230411_152532.jpg\n",
      "Features extracted for blurred_IMG_20230411_152904.jpg\n",
      "Features extracted for blurred_IMG_20230411_153308.jpg\n",
      "Features extracted for blurred_IMG_20230411_153708.jpg\n",
      "Features extracted for blurred_IMG_20230411_153758.jpg\n",
      "Features extracted for blurred_IMG_20230411_154000.jpg\n",
      "Features extracted for blurred_IMG_20230411_154016.jpg\n",
      "Features extracted for blurred_IMG_20230411_154103.jpg\n",
      "Features extracted for blurred_IMG_20230411_154108.jpg\n",
      "Features extracted for blurred_IMG_20230411_154115.jpg\n",
      "Features extracted for blurred_IMG_20230411_154807.jpg\n",
      "Features extracted for blurred_IMG_20230413_130827.jpg\n",
      "Features extracted for blurred_IMG_20230413_130834.jpg\n",
      "Features extracted for blurred_IMG_20230413_130916.jpg\n",
      "Features extracted for blurred_IMG_20230413_131156.jpg\n",
      "Features extracted for denoised_IMG_20230410_130327.jpg\n",
      "Features extracted for denoised_IMG_20230410_130352.jpg\n",
      "Features extracted for denoised_IMG_20230410_130733.jpg\n",
      "Features extracted for denoised_IMG_20230410_130823.jpg\n",
      "Features extracted for denoised_IMG_20230410_130913.jpg\n",
      "Features extracted for denoised_IMG_20230410_131008.jpg\n",
      "Features extracted for denoised_IMG_20230410_131353.jpg\n",
      "Features extracted for denoised_IMG_20230410_132726.jpg\n",
      "Features extracted for denoised_IMG_20230410_132758.jpg\n",
      "Features extracted for denoised_IMG_20230410_132823.jpg\n",
      "Features extracted for denoised_IMG_20230410_134317.jpg\n",
      "Features extracted for denoised_IMG_20230410_134343.jpg\n",
      "Features extracted for denoised_IMG_20230410_134455.jpg\n",
      "Features extracted for denoised_IMG_20230410_134518.jpg\n",
      "Features extracted for denoised_IMG_20230410_135002.jpg\n",
      "Features extracted for denoised_IMG_20230410_135018.jpg\n",
      "Features extracted for denoised_IMG_20230410_135707.jpg\n",
      "Features extracted for denoised_IMG_20230410_140201_1.jpg\n",
      "Features extracted for denoised_IMG_20230410_141229.jpg\n",
      "Features extracted for denoised_IMG_20230410_141237.jpg\n",
      "Features extracted for denoised_IMG_20230410_141253.jpg\n",
      "Features extracted for denoised_IMG_20230410_141341.jpg\n",
      "Features extracted for denoised_IMG_20230410_141350.jpg\n",
      "Features extracted for denoised_IMG_20230410_141456.jpg\n",
      "Features extracted for denoised_IMG_20230410_141525.jpg\n",
      "Features extracted for denoised_IMG_20230410_141604.jpg\n",
      "Features extracted for denoised_IMG_20230410_141612.jpg\n",
      "Features extracted for denoised_IMG_20230410_141617.jpg\n",
      "Features extracted for denoised_IMG_20230410_141657.jpg\n",
      "Features extracted for denoised_IMG_20230410_141801.jpg\n",
      "Features extracted for denoised_IMG_20230410_141919.jpg\n",
      "Features extracted for denoised_IMG_20230410_142011.jpg\n",
      "Features extracted for denoised_IMG_20230410_142016.jpg\n",
      "Features extracted for denoised_IMG_20230410_143128.jpg\n",
      "Features extracted for denoised_IMG_20230410_143146.jpg\n",
      "Features extracted for denoised_IMG_20230410_143505.jpg\n",
      "Features extracted for denoised_IMG_20230411_152532.jpg\n",
      "Features extracted for denoised_IMG_20230411_152904.jpg\n",
      "Features extracted for denoised_IMG_20230411_153308.jpg\n",
      "Features extracted for denoised_IMG_20230411_153708.jpg\n",
      "Features extracted for denoised_IMG_20230411_153758.jpg\n",
      "Features extracted for denoised_IMG_20230411_154000.jpg\n",
      "Features extracted for denoised_IMG_20230411_154016.jpg\n",
      "Features extracted for denoised_IMG_20230411_154103.jpg\n",
      "Features extracted for denoised_IMG_20230411_154108.jpg\n",
      "Features extracted for denoised_IMG_20230411_154115.jpg\n",
      "Features extracted for denoised_IMG_20230411_154807.jpg\n",
      "Features extracted for denoised_IMG_20230413_130827.jpg\n",
      "Features extracted for denoised_IMG_20230413_130834.jpg\n",
      "Features extracted for denoised_IMG_20230413_130916.jpg\n",
      "Features extracted for denoised_IMG_20230413_131156.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_130327.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_130352.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_130733.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_130823.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_130913.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_131008.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_131353.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_132726.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_132758.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_132823.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_134317.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_134343.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_134455.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_134518.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_135002.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_135018.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_135707.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_140201_1.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141229.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141237.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141253.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141341.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141350.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141456.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141525.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141604.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141612.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141617.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141657.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141801.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_141919.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_142011.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_142016.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_143128.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_143146.jpg\n",
      "Features extracted for median_filtered_IMG_20230410_143505.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_152532.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_152904.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_153308.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_153708.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_153758.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_154000.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_154016.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted for median_filtered_IMG_20230411_154103.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_154108.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_154115.jpg\n",
      "Features extracted for median_filtered_IMG_20230411_154807.jpg\n",
      "Features extracted for median_filtered_IMG_20230413_130827.jpg\n",
      "Features extracted for median_filtered_IMG_20230413_130834.jpg\n",
      "Features extracted for median_filtered_IMG_20230413_130916.jpg\n",
      "Features extracted for median_filtered_IMG_20230413_131156.jpg\n",
      "Feature extraction completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the preprocessed images directory\n",
    "preprocessed_dir = 'preprocessed_images'\n",
    "\n",
    "# Specify the path to the output directory for extracted features\n",
    "output_dir = 'extracted_features2'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Iterate over the preprocessed image files\n",
    "for root, dirs, files in os.walk(preprocessed_dir):\n",
    "    for file_name in files:\n",
    "        # Read the preprocessed image\n",
    "        image_path = os.path.join(root, file_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Perform feature extraction (e.g., SIFT, SURF, or CNN-based feature extraction)\n",
    "        # Example using SIFT\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        sift = cv2.SIFT_create()\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "        # Save the extracted features\n",
    "        feature_file = os.path.join(output_dir, f'{file_name}.npy')\n",
    "        np.save(feature_file, descriptors)\n",
    "\n",
    "        print(f\"Features extracted for {file_name}\")\n",
    "\n",
    "print(\"Feature extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14408733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd15df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "preprocessed_dir = 'preprocessed_images'\n",
    "labels_file = 'labels.txt'\n",
    "\n",
    "# Get the unique labels from the image file names\n",
    "labels = set()\n",
    "for root, dirs, files in os.walk(preprocessed_dir):\n",
    "    for file_name in files:\n",
    "        label = file_name.split('_')[1].split('.')[0]\n",
    "        labels.add(label)\n",
    "\n",
    "# Save the labels to the labels file\n",
    "with open(labels_file, 'w') as f:\n",
    "    f.write('\\n'.join(sorted(labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a49009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SK VERMA\\AppData\\Local\\Temp\\ipykernel_47528\\1664330166.py:39: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(image_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 32s 7s/step - loss: 15.8647 - accuracy: 0.8381 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 1.6238 - accuracy: 0.6381 - val_loss: 1.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 27s 7s/step - loss: 0.4390 - accuracy: 0.8381 - val_loss: 1.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.3413 - accuracy: 0.8381 - val_loss: 2.6650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.3139 - accuracy: 0.8571 - val_loss: 3.9397 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.2431 - accuracy: 0.8571 - val_loss: 3.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.2674 - accuracy: 0.8571 - val_loss: 1.1544 - val_accuracy: 0.4074\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.2442 - accuracy: 0.9048 - val_loss: 3.1478 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 26s 6s/step - loss: 0.2751 - accuracy: 0.8857 - val_loss: 1.0660 - val_accuracy: 0.1481\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 25s 6s/step - loss: 0.1773 - accuracy: 0.9619 - val_loss: 0.7320 - val_accuracy: 0.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182f0ec3400>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import imageio\n",
    "from skimage.filters import gaussian\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.morphology import disk\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Path to the preprocessed images directory\n",
    "preprocessed_dir = 'preprocessed_images'\n",
    "\n",
    "# Path to the labels file\n",
    "labels_file = 'labels.txt'\n",
    "\n",
    "# Load the labels\n",
    "with open(labels_file, 'r') as f:\n",
    "    labels = f.read().splitlines()\n",
    "\n",
    "# Create a mapping from labels to numerical values\n",
    "label_to_index = {label: index for index, label in enumerate(labels)}\n",
    "\n",
    "# Initialize empty lists to store image data and corresponding labels\n",
    "images = []\n",
    "image_labels = []\n",
    "\n",
    "# Iterate over the preprocessed images directory\n",
    "for root, dirs, files in os.walk(preprocessed_dir):\n",
    "    for file_name in files:\n",
    "        # Load the image\n",
    "        image_path = os.path.join(root, file_name)\n",
    "        image = imageio.imread(image_path)\n",
    "        \n",
    "        # Append the image data to the list\n",
    "        images.append(image)\n",
    "        \n",
    "        # Extract the label from the file name\n",
    "        label = file_name.split('_')[1].split('.')[0]\n",
    "        \n",
    "        # Map the label to its numerical value\n",
    "        label_index = label_to_index[label]\n",
    "        \n",
    "        # Append the label index to the list\n",
    "        image_labels.append(label_index)\n",
    "\n",
    "# Convert the image and label lists to numpy arrays\n",
    "images = np.array(images)\n",
    "image_labels = np.array(image_labels)\n",
    "\n",
    "# Normalize the image data\n",
    "images = images / 255.0\n",
    "\n",
    "# Convert the labels to categorical format\n",
    "num_classes = len(labels)\n",
    "image_labels = to_categorical(image_labels, num_classes=num_classes)\n",
    "\n",
    "# Split the dataset into training and testing sets (80% for training, 20% for testing)\n",
    "split_idx = int(0.8 * len(images))\n",
    "train_images, test_images = images[:split_idx], images[split_idx:]\n",
    "train_labels, test_labels = image_labels[:split_idx], image_labels[split_idx:]\n",
    "image_height, image_width, _ = images[0].shape\n",
    "# Create the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "220b51d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.7320 - accuracy: 0.4444\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         IMG       0.00      0.00      0.00         0\n",
      "    filtered       1.00      0.44      0.62        27\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.50      0.22      0.31        27\n",
      "weighted avg       1.00      0.44      0.62        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert true labels to class labels\n",
    "true_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Calculate the metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=labels)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed6708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.7320 - accuracy: 0.4444\n",
      "Accuracy: 0.4444444477558136\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3d56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
